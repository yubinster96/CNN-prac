{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80020750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30d5866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anac\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "#initializing the CNN\n",
    "classifier=Sequential()\n",
    "#convolution step1.. the input shape 64,64,3 means its 64x64 pixel and each pixel has 3 values..this is import our input shape has to match\n",
    "#our data size.. otherwise we will get errors... relu is commonly used since its fast\n",
    "\n",
    "classifier.add(Conv2D(32,(3,3), input_shape = (64,64,3), activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c42288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#adding a second convolutional layer\n",
    "classifier.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
    "#mapping and reducing.. we want to reduce it to 2 sets.. from the 3 values to 2 dimension..\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7534a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening.. we resizing from 3d to 2d and now we flattening to one array\n",
    "classifier.add(Flatten())\n",
    "#full connection.. 64+64=128..\n",
    "classifier.add(Dense(units=128,activation=\"relu\"))\n",
    "#filter it to 1 unit.. eg 1 is dog 0 is cat.. sigmoid is yes or no\n",
    "classifier.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "#compiling the CNN.. optimize is reverse propogation.. adam is most commonly used and good for big data\n",
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3cef043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the CNN to the images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator (rescale = 1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be484840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\"C:\\\\Users\\\\akkim\\\\Desktop\\\\training_set\",\n",
    "                                               target_size =(64,64),\n",
    "                                               batch_size=32,\n",
    "                                               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3fa340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_set=train_datagen.flow_from_directory(\"C:\\\\Users\\\\akkim\\\\Desktop\\\\test_set\",\n",
    "                                         target_size=(64,64),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e4148c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anac\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 247/8000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:51\u001b[0m 76ms/step - accuracy: 0.5677 - loss: 0.6781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anac\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.6503 - val_accuracy: 0.6725 - val_loss: 0.6218\n",
      "Epoch 2/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.5805 - val_accuracy: 0.6570 - val_loss: 0.6206\n",
      "Epoch 3/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5434 - val_accuracy: 0.7410 - val_loss: 0.5275\n",
      "Epoch 4/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5234 - val_accuracy: 0.7290 - val_loss: 0.5224\n",
      "Epoch 5/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.5047 - val_accuracy: 0.7410 - val_loss: 0.5168\n",
      "Epoch 6/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7707 - loss: 0.4820 - val_accuracy: 0.7605 - val_loss: 0.5109\n",
      "Epoch 7/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.4674 - val_accuracy: 0.7655 - val_loss: 0.4871\n",
      "Epoch 8/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4463 - val_accuracy: 0.7720 - val_loss: 0.4681\n",
      "Epoch 9/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.4421 - val_accuracy: 0.7790 - val_loss: 0.4690\n",
      "Epoch 10/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.4273 - val_accuracy: 0.7765 - val_loss: 0.4661\n",
      "Epoch 11/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4112 - val_accuracy: 0.7805 - val_loss: 0.4604\n",
      "Epoch 12/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.4002 - val_accuracy: 0.7875 - val_loss: 0.4617\n",
      "Epoch 13/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3790 - val_accuracy: 0.7890 - val_loss: 0.4482\n",
      "Epoch 14/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.3780 - val_accuracy: 0.7895 - val_loss: 0.4553\n",
      "Epoch 15/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.3611 - val_accuracy: 0.7830 - val_loss: 0.4589\n",
      "Epoch 16/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3445 - val_accuracy: 0.7985 - val_loss: 0.4478\n",
      "Epoch 17/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3390 - val_accuracy: 0.7920 - val_loss: 0.4991\n",
      "Epoch 18/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3256 - val_accuracy: 0.7810 - val_loss: 0.4807\n",
      "Epoch 19/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3280 - val_accuracy: 0.8005 - val_loss: 0.4423\n",
      "Epoch 20/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3077 - val_accuracy: 0.8015 - val_loss: 0.4546\n",
      "Epoch 21/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.2960 - val_accuracy: 0.7860 - val_loss: 0.4786\n",
      "Epoch 22/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2775 - val_accuracy: 0.8110 - val_loss: 0.4669\n",
      "Epoch 23/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2690 - val_accuracy: 0.7935 - val_loss: 0.4853\n",
      "Epoch 24/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8911 - loss: 0.2575 - val_accuracy: 0.7795 - val_loss: 0.5272\n",
      "Epoch 25/25\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2473 - val_accuracy: 0.7875 - val_loss: 0.5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f560beb890>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "classifier.fit(training_set,\n",
    "                        steps_per_epoch=8000,\n",
    "                        epochs=25,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14d03884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    }
   ],
   "source": [
    "#also if accuracy goes down and val acc goes up as epoch tests continue means theres bias\n",
    "# now on to making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img(\"C:\\\\Users\\\\akkim\\\\Desktop\\\\cat_or_dog_1.jpg\",\n",
    "                          target_size=(64,64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "#put into single array\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]==1:\n",
    "    prediction=\"dog\"\n",
    "else:\n",
    "    prediction=\"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02aae0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1717d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
